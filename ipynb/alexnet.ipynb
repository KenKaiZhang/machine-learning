{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of AlexNet introduced by Alex Krizevsky in the paper **\"ImageNet Classification with Deep Convolutional Neural Networks\"**. This notebook is meant for me to take notes on dansuh17 implementation of the network found [here](https://github.com/dansuh17/alexnet-pytorch/blob/d0c1b1c52296ffcbecfbf5b17e1d1685b4ca6744/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading the necessary libraries from `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install Pillow\n",
    "%pip install protobuf\n",
    "%pip install six\n",
    "%pip install torch\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great now let's import the required libraries into our notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "# Torchvision will sometimes give you errors. Just reinstall it\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "# from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch allows us to execute their code on either the CPU or GPU so let's set that up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we needs to define some parameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 90\n",
    "BATCH_SIZE = 128\n",
    "MOMENTUM = 0.9\n",
    "LR_DECAY = 0.0005\n",
    "LR_INIT = 0.01\n",
    "IMAGE_DIM = 227\n",
    "NUM_CLASSES = 1000\n",
    "DEVICE_IDS = [0, 1, 2, 3]\n",
    "INPUT_ROOT_DIR = 'alexnet_data_in'\n",
    "TRAIN_IMG_DIR = 'alexnet_data_in/imagenet'\n",
    "OUTPUT_DIR = 'alexnext_data_out'\n",
    "CHECKPOINT_DIR = OUTPUT_DIR + '/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review what each parameter defines.\n",
    "\n",
    "- `NUM_EPOCHS` : number of times the dataset should run through the model (1 epoch = 1 time data passes through the model)\n",
    "- `BATCH_SIZE` : number of samples used in one forward and backward pass through the network\n",
    "- `MOMENTUM` : additional parameter that accelerates the gradient descent in a particular direction\n",
    "- `LR_DECAY` : how much the learning rate will decrease over time in training\n",
    "- `LR_INIT` : learning rate\n",
    "- `IMAGE_DIM` : dimensions of the input image\n",
    "- `NUM_CLASSES` : number of classes for predictable by the model\n",
    "- `DEVICE_IDS` : identifiers for each processing unit\n",
    "- `INPUT_ROOT_DIR` : root directory where input data is stored\n",
    "- `TRAIN_IMG_DIR` : directory where the training images are stored\n",
    "- `OUTPUT_DIR` : where the model outputs will be saved\n",
    "- `CHECKPOINT_DIR` : place to store model checkpoints (includes model parameters ate various stages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the folder that will containe the checkpoint data\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here's a quick overview of Alexnet.\n",
    "\n",
    "The overall **MAIN** architecture of AlexNet contains eight layers with weights.\n",
    "\n",
    "- 5 convolutional\n",
    "- 3 fully connected (used for classifying input images into a label)\n",
    "\n",
    "Neurons in each fully connected layer are only connected to all neurons in its previous layer.\n",
    "\n",
    "- The final fully connected layer is fed to a 1000-way softmax that produces a distribution over 1000 class labels\n",
    "\n",
    "Each convolutional layer has their own kernels (nxn matrix of number used to filter information from the image). \n",
    "\n",
    "- **2nd**, **4th**, and **5th** layers have their kernels connected to the kernel maps in the previous layer that are on the same GPU\n",
    "- **3rd** layer has all its kernels connected to all kernel maps in the 2nd layer\n",
    "\n",
    "Throughout the main architecture, mixes of Response-normalization, Max-pooling, and ReLU non-linearity layers are placed in between.\n",
    "\n",
    "- Response-normalization layer : will normalize the activaitons of its previous layers\n",
    "    - activations are scaled and shifted to have a standard normal distribution ( mean = 0 , variance = 1)\n",
    "    - increases the sensory perception at points of interest\n",
    "    - useful to be placed right after ReLU layers since they have unbounded activations\n",
    "- Max-pooling layer : calculates the maximum value for patches of the feature map\n",
    "- ReLU non-linearity layer : linear activation function that basically does f(x) = max(0, x)\n",
    "    - solves the vanishing gradient problem since gradient will always be 0 or positive\n",
    "    - has unbounded activations (solved with normalization)\n",
    "\n",
    "With that in mind let's code it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network model with layers proposed by AlexNet paper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input image should be (b x 3 x 277 x 277)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),    # (b x 96 x 55 x 55)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
    "            nn.Conv2d(96, 256, 5, padding=2),   # (b x 256 x 27 x 27)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2), \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 384 x 13 x 13)\n",
    "            nn.Conv2d(256, 384, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)   # (b x 256 x 6 x 6)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def init_bias(self):\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "        nn.init.constant_(self.net[4].bias, 1)\n",
    "        nn.init.constant_(self.net[10].bias, 1)\n",
    "        nn.init.constant_(self.net[12].bias, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "With our AlexNet, let's see how we can train it and have it classify images.\n",
    "\n",
    "First we make some initial setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = torch.initial_seed()\n",
    "print(f\"Current seed : {seed}.\")\n",
    "\n",
    "# Create the mode\n",
    "alexnet = AlexNet(num_clases=NUM_CLASSES).to(device)\n",
    "# Train the model on multiple GPUs\n",
    "alexnet = torch.nn.parallel.DataParallel(alexnet, device_ids=DEVICE_IDS)\n",
    "print(f\"AlexNet created : {alexnet}.\")\n",
    "\n",
    "dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n",
    "    transforms.CenterCrop(IMAGE_DIM),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "]))\n",
    "print(\"Dataset created.\")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    "    drop_last=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "print(\"Dataloader created.\")\n",
    "\n",
    "optimizer = optim.Adam(params=alexnet.parameters(), lr=0.0001)\n",
    "print(\"Optimizer created.\")\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "print(\"LR Scheduler created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 points of interest in the code above, let's take a look at each one.\n",
    "\n",
    "```python\n",
    "dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n",
    "    transforms.CenterCrop(IMAGE_DIM),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "]))\n",
    "```\n",
    "\n",
    "`datasets.ImageFolder` is a `torchvision.datasets` module designed the handle images in a directory organized by their class labels (each class has their own directory). This method contains the path of the data and a \"list\" of transforms operatios that should be applied to each image in the dataset.\n",
    "\n",
    "- `CenterCrop` : crops image to size `IMAGE_DIM` around the center\n",
    "- `ToTensor` : converts the data to a PyTorch tensor (makes it so PyTorch can work with the data)\n",
    "- `Normalizer` : normalizes the tensor image with mean and standard deviation values to make sure data has zero mean and unit variance\n",
    "\n",
    "```python\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    "    drop_last=True,\n",
    "    batch_size=BATCH_SIZE\n",
    "\n",
    ")\n",
    "```\n",
    "\n",
    "`data.Dataloader` sets up a PyTorch object that will efficiently load and iterate over batches of data during the training process\n",
    "\n",
    "- `dataset` : the dataset\n",
    "- `shuffle` : data will be shuffled on every epoch\n",
    "- `pin_memory` : whether to use pinned memory for faster data transfwer to the GPU\n",
    "    - **pinned memory** : memory that is allocated and locked only for GPU usage\n",
    "- `drop_last` : will drop the last incomplete batch if the dataset size is not divisible by the batch size\n",
    "- `batch_size` : specifies the number of samples per batch\n",
    "\n",
    "```python\n",
    "optimizer = optim.Adam(params=alexnet.parameters(), lr=0.0001)\n",
    "```\n",
    "\n",
    "AlexNet utilizes the **Adam Optimizer**, a very popular option for tuning parameters during training. This optimizer combines 2 versions of stochastic gradient descent:\n",
    "\n",
    "- Adaptive Gradient Algorithm (AdaGrad) : maintains a per-parameter learning rate\n",
    "- Root Mean Square Propagation (RMSProp) : maintains per-parameter learning rates that are adapted based on the average of recent magnitudes\n",
    "\n",
    "In out AlexNext implementation, we are having it our Adam optimizer adjust parameters in `alexnet.parameters` at a learning rate of 0.0001\n",
    "\n",
    "```python\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "```\n",
    "\n",
    "This schedular will give as a dynamic learning rate. With the parameters given, our Adam optimizer will now adjust the learning rate by 0.1 for every 30 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training start...\")\n",
    "\n",
    "total_steps = 1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    lr_scheduler.step()\n",
    "    for imgs, classes in dataloader:\n",
    "        imgs, classes = imgs.to(device), classes.to(device)\n",
    "\n",
    "        # Calculate the loss\n",
    "        output = alexnet(imgs)\n",
    "        loss = F.cross_entropy(output, classes)\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out gradient values and parameter average values\n",
    "        if total_steps % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                print(\"*\" * 10)\n",
    "                for name, parameter in alexnet.named_parameters():\n",
    "                    if parameter.grad is not None:\n",
    "                        avg_grad = torch.mean(parameter.grad)\n",
    "                        print(f\"\\t{name} - grad_avg: {avg_grad}\")\n",
    "                    if parameter.data is not None:\n",
    "                        avg_weight = torch.mean(parameter.data)\n",
    "                        print(f\"\\t{name} - param_avg: {avg_weight}\")\n",
    "        total_steps += 1\n",
    "\n",
    "    # Save checkpoints\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"alexnet_states_e{epoch + 1}.pkl\")\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"total_steps\": total_steps,\n",
    "        \"optimizer\" : optimizer,\n",
    "        \"model\": alexnet.state_dict(),\n",
    "        \"seed\": seed\n",
    "    }\n",
    "    torch.save(state, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's breakdown the training process.\n",
    "\n",
    "1. Check if we need to update the parameter with `lr_scheduler.step()`. This method will only update if the epoch matches the set scheduler.\n",
    "2. `for` each img in our dataset (and their corresponding class) \n",
    "    - Run them on the GPU if available\n",
    "    - Predict with the training set\n",
    "    - Get the loss by using the predictions from the training set and the desired outputs\n",
    "    - Zero out the gradients on the optimizer (makes sure we are not retaining previous information)\n",
    "    - Compute the gradients of the loss\n",
    "    - Update parameters based on back propagation calculations\n",
    "3. Save the progress for the epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
