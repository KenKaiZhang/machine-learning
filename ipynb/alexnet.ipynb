{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of AlexNet introduced in **ImageNet Classification with Deep Convolutional Neural Networks** found [here](https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html). This notebook is just a way for me to understand my code found in `alexnet.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ken zhang\\onedrive\\documents\\git\\machine-learning\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet's architecture can be found in the papers in the diagram or just by reading it. Layed out it looks like this:\n",
    "\n",
    "```\n",
    "Convolutional Layer\n",
    "ReLU\n",
    "Response Normalization Layer\n",
    "MaxPool Layer\n",
    "\n",
    "Convolutional Layer\n",
    "ReLU\n",
    "Response Normalization Layer\n",
    "MaxPool Layer\n",
    "\n",
    "Convolutional Layer\n",
    "ReLU\n",
    "\n",
    "Convloutional Layer\n",
    "ReLU\n",
    "\n",
    "Convolutional Layer\n",
    "ReLU\n",
    "MaxPool Layer\n",
    "\n",
    "Dropout\n",
    "Fully-Connected Layer\n",
    "ReLU\n",
    "\n",
    "Dropout\n",
    "Fully-Connected Layer\n",
    "ReLU\n",
    "\n",
    "Fully-Connected Layer\n",
    "ReLU\n",
    "\n",
    "1000-way Softmax\n",
    "```\n",
    "With this layout, we can first construct a template for this architecture:\n",
    "\n",
    "```python\n",
    "class AlexNet(nn.Module):\n",
    "    self.conv1 = nn.Conv2d()\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.norm1 = nn.LocalResponseNorm()\n",
    "    self.maxp1 = nn.MaxPool2d()\n",
    "\n",
    "    self.conv2 = nn.Conv2d()\n",
    "    self.relu2 = nn.ReLU()\n",
    "    self.norm2 = nn.LocalResponseNorm()\n",
    "    self.maxp2 = nn.MaxPool2d()\n",
    "\n",
    "    self.conv3 = nn.Conv2d()\n",
    "    self.relu3 = nn.ReLU()\n",
    "\n",
    "    self.conv4 = nn.Conv2d()\n",
    "    self.relu4 = nn.ReLU()\n",
    "\n",
    "    self.conv5 = nn.Conv2d()\n",
    "    self.relu5 = nn.ReLU()\n",
    "    self.maxp5 = nn.MaxPool2d()\n",
    "\n",
    "    self.dropf1 = nn.Dropout()\n",
    "    self.fc1 = nn.Linear()\n",
    "    self.reluf1 = nn.ReLU()\n",
    "\n",
    "    self.dropf2 = nn.Dropout()\n",
    "    self.fc2 = nn.Linear()\n",
    "    self.reluf2 = nn.Linear()\n",
    "\n",
    "    self.fc3 = nn.Linear()\n",
    "```\n",
    "With this, we can fill in the arguments for each module by reading the paper to get the fully completed code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.norm1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "        self.maxp1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.norm2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "        self.maxp2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.maxp5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.dropf1 = nn.Dropout(p=0.5, inplace=True)\n",
    "        self.fc1 = nn.Linear(in_features=(256 * 6 * 6), out_features=4096)\n",
    "        self.reluf1 = nn.ReLU()\n",
    "        self.dropf2 = nn.Dropout(p=0.5, inplace=True)\n",
    "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
    "        self.reluf2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=4096, out_features=1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.maxp1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.maxp2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.maxp5(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.dropf1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.reluf1(x)\n",
    "        x = self.dropf2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.reluf2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything can be found in the paper other than the paddings which the author does not mention (for some reason), but they are used in all convolutional layers with sizes `[2, 2, 1, 1, 1]` respectively.\n",
    "\n",
    "Also note that before we can pass the input from the last convolutional layer to the first fully-connected layer, we have to flatten it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model by passing a dummy tensor of size `[2, 3, 244, 244]` which represents two 244x244 RGB images. We know the model works when this dummy tensor passes through the model without triggering an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    net = AlexNet()\n",
    "    x = torch.randn(2, 3, 224, 224)\n",
    "    y = net(x).to('cuda')\n",
    "    print(y.shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
