{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of GoogLeNet that won the **\"ImageNet Classification with Deep Convolutional Neural Networkds\"** in 2014. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading the necessary libraries from `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's import the requried libraries into our notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Optional, Tuple, Any\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since training will be on in a different file and use the modules from this file, let's state which module should be exported if a were to utilize this one. By setting an `__all__`, we can let Python know that any other modules (functions, classes, etc) that exists in the file but outside the list should not be accessible by files that will utilize this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"GoogleNetOutputs\",\"GoogLeNet\", \"BasicConv2d\", \"Inception\", \"InceptionAux\", \"googlenet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with organization with the model's outputs, we explicitly define what we want our model output to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogLeNetOutputs = namedtuple(\"GoogLeNetOutputs\", [\"logits\", \"aux_logits2\", \"aux_logits1\"])\n",
    "GoogLeNetOutputs.__annotations__ = {\n",
    "    \"logits\": Tensor,\n",
    "    \"aux_logits2\": Optional[Tensor],\n",
    "    \"aux_logits1\": Optional[Tensor]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code above, we state that we want our outputs to be stored in the variable `GoogLeNetOutputs` where the data contained should be a tuple of 3 `Tensor`s where 2 of them can either be a `Tenor` or `None`.\n",
    "\n",
    "With that, we can begin building GoogLeNet model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First there are a few components we need to build before getting to the network. The following classes:\n",
    "\n",
    "- `BasicConv2d1`\n",
    "- `Inception`\n",
    "- `InceptionAux`\n",
    "\n",
    "Let's explore each one in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convolutional layers in GoogLeNet, we will be using this \"custom\" layer instead of the normal `nn.Conv2d` to help improve the stability and capabilities of our model. Now let's break down the code.\n",
    "\n",
    "Our new convolutional layer takes in 3 parameters:\n",
    "\n",
    "- `in_channels` : the dpeth of the input feature map\n",
    "- `out_channels` : the depth of the output feature map\n",
    "- `**kwargs` : any additional parameters to be added to `nn.Con2d`\n",
    "\n",
    "Let's explore what happens when data is passes through the `forward` function.\n",
    "\n",
    "1. Assume a input `x` representing a batch of images or feature maps of size (N, C, H, W) where:\n",
    "    - N : batch size (number of images)\n",
    "    - C : depth of the input (input channels)\n",
    "    - H : height of each image / feature map\n",
    "    - W : width of each image / feature map\n",
    "2. The input tensor `x` is passed to a `nn.Conv2d` layer where kernel operations are performed on it, resulting in a new tensor of shape (N, C, H, W) where:\n",
    "    - N : batch size\n",
    "    - C : depth of input (determined by number of kernels)\n",
    "    - H/W : new dimensions of the image / feature map\n",
    "3. `nn.BatchNorm2d` applies normalization to the tensor, stanardizing all feature maps to have a mean of 0 and a standard deviation of 1\n",
    "4. Non-linearity is introduced through ReLU activation\n",
    "\n",
    "_Note: when a convolutional layer returns a tensor of (N, C, H, W), we can think of it like : **Each batch contains N feature map/images where EACH SAMPLE in the batch has C features learned represented in a spatial structure of H x W**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        ch1x1: int,\n",
    "        ch3x3red: int,\n",
    "        ch3x3: int,\n",
    "        ch5x5red: int,\n",
    "        ch5x5: int,\n",
    "        pool_proj: int\n",
    "    ) -> None:\n",
    "        super(Inception, self).__init__()\n",
    "        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, ch3x3red, kernel_size=(1,1), stride=(1,1), padding=(0,0)),\n",
    "            BasicConv2d(ch3x3red, ch3x3, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, ch5x5red, kernel_size=(1,1), stride=(1,1), padding=(0,0)),\n",
    "            BasicConv2d(ch5x5red, ch5x5, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=(1,1), padding=(1,1), ceil_mode=True),\n",
    "            BasicConv2d(in_channels, pool_proj, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        out = [branch1, branch2, branch3, branch4]\n",
    "        out = torch.cat(out, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Inception module is the key to GoogLeNet. Let's see how it works.\n",
    "\n",
    "The modules contains 4 branches, each of which processes the input in a different way.\n",
    "\n",
    "1. Branch 1 : 1x1 convolutional layer used to capture features at a small spatial scale\n",
    "2. Branch 2 : 1x1 convolutional layer that outputs directly to a 3x3 convolutional layer\n",
    "    - 1x1 reduces the number of input channels\n",
    "    - 3x3 captures the spatial features\n",
    "3. Branch 3 : similar to branch 2 but from a 1x1 to a 5x5\n",
    "4. Branch 4 : max-pooling to capture larger spatial feature and gets dimensionally reduced by a 1x1 convolution\n",
    "\n",
    "When making the forward pass, the each branch does their own computation and all the branches are then concatenated along the channel dimension using `torch.cat`\n",
    "\n",
    "The last part may be a little confusing so let me explain.\n",
    "\n",
    "With 4 branches, we will have 4 tensors of size (N, C, H, W) where:\n",
    "- N : batch size\n",
    "- C : number of input channels\n",
    "- H/W : dimensions of the feature maps\n",
    "\n",
    "Each tensor has a different C based on the branch it was produced. By concatenating, the resulting tensor will be (N, C1 + ... + Cn, H, W), which can be interpreted as having **N images where each image has Ctotal features detected where each feature is represented in HxW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionAux(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            num_classes: int,\n",
    "            dropout: float = 0.7\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n",
    "        self.conv = BasicConv2d(in_channels, 128, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout, True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        out = self.avgpool(x)\n",
    "        out = self.conv(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final component of our GoogLeNet. First let's figure out what is the difference between `Inception` and `InceptionAux`.\n",
    "\n",
    "**Auxiliary Classifiers** are classifiers that are used to improve the convergence of very deep netowrks by pushing useful gradients to the lower layers, **combatting the vanishig gradient problem**. We add auxiliary classifiers usually towards the end of the network, creating another waay for the network to backpropagate.\n",
    "\n",
    "Another way to think about it is that they introduce additional feedback signals that can be used to adjust weights, giving lower layers more fine-tuning.\n",
    "\n",
    "Let's breakdown what the `InceptionAux` class does.\n",
    "\n",
    "Like the previous components, this class is constructed with multiple layers so let's see what happens when we pass an input tensor into this \"network\".\n",
    "\n",
    "1. The adaptive average pooling layer will reduce the spatial dimension to 4x4\n",
    "    - Think of this like a max-pooling layer where we can define the output dimensions\n",
    "    - The stride + kernel size to make it happen is automatically selected\n",
    "2. The result is passed through a 1x1 convolutional layer\n",
    "3. The convolutional layer result is then flattened and ReLU\n",
    "    - It is necessary to flatten convolutional results before passing it onto fully-connected layers\n",
    "4. Dropout is applied after the first fully-connected layer\n",
    "5. The final fully-connected layer produces the final class scores\n",
    "\n",
    "The results of this class should be an ouput that corresponds with the number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! With all our components ready, it is time to build up GoogLeNet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    __constants__ = [\"aux_logits\", \"transform_input\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 1000,\n",
    "        aux_logits: bool = True,\n",
    "        transform_input: bool = False,\n",
    "        dropout: float = 0.2,\n",
    "        dropout_aux: float = 0.7\n",
    "    ) -> None:\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "        self.conv1 = BasicConv2d(2, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
    "        self.maxpool1 = nn.MaxPool2d((3,3), (2,2), ceil_mode=True)\n",
    "        self.conv2 = BasicConv2d(64, 64, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "        self.conv3 = BasicConv2d(64, 192, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.maxpool2 = nn.MaxPool2d((3,3), (2,2), ceil_mode=True)\n",
    "\n",
    "        self.inception3a = Inception(192, 64, 98, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d((3,3), (2,2), ceil_mode=True)\n",
    "\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 48)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d((2,2), (2,2), ceil_mode=True)\n",
    "\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        if aux_logits:\n",
    "            self.aux1 = InceptionAux(512, num_classes, dropout_aux)\n",
    "            self.aux2 = InceptionAux(528, num_classes, dropout_aux)\n",
    "        else:\n",
    "            self.aux1 = None\n",
    "            self.aux2 = None\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(dropout, True)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x: Tensor, aux2: Tensor, aux1: Optional[Tensor]) -> GoogLeNetOutputs | Tensor:\n",
    "        if self.training and self.aux_logits:\n",
    "            return GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
    "        out = self._forward_impl(x)\n",
    "        return out\n",
    "    \n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "    \n",
    "    def _forward_imp1(self, x: Tensor) -> GoogLeNetOutputs:\n",
    "        x = self._transform_input(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        out = self.inception3a(out) \n",
    "        out = self.inception3b(out)\n",
    "        out = self.maxpool3(out)\n",
    "        out = self.inception4a(out)\n",
    "        aux1: Optional[Tensor] = self.aux1(out) if self.aux1 is not None and self.training else None\n",
    "\n",
    "        out = self.inception4b(out)\n",
    "        out = self.inception4c(out)\n",
    "        out = self.inception4d(out)\n",
    "        aux2: Optional[Tensor] = self.aux2(out) if self.aux1 is not None and self.training else None\n",
    "\n",
    "        out = self.inception4e(out) \n",
    "        out = self.maxpool4(out)\n",
    "        out = self.inception5a(out)\n",
    "        out = self.inception5b(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.dropout(out)\n",
    "        aux3 = self.fc(out)\n",
    "\n",
    "        if torch.jit.is_scripting():\n",
    "            return GoogLeNetOutputs(aux3, aux2, aux1)\n",
    "        else:\n",
    "            return self.eager_outputs(aux3, aux2, aux1)\n",
    "        \n",
    "    def _initialize_weights(self) -> None:\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                torch.nn.init.trunc_normal_(module.weight, mean=0.0, std=0.1, a=-1, b=2)\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation follows the diagram shown in the GoogLeNet papers, but here are some key things to note.\n",
    "\n",
    "**`eager_outputs`**\n",
    "\n",
    "Determines the format of the output during the forward pass and will only be used when model is in training mode.\n",
    "\n",
    "**`_transform_input`**\n",
    "\n",
    "Normalizes the input tensor `x`, by normalizing each channel (R,G,B) individually and then concatinating the results.\n",
    "\n",
    "The constant used in the calculation are typical mean and standared deviation values derived from ImageNet.\n",
    "\n",
    "- Mean : [0.485, 0.456, 0.406]\n",
    "- Standard Deviation : [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model built, let's see how we can train it.\n",
    "\n",
    "Let's start by importing the libraries we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.cuda import amp\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import config\n",
    "from dataset import CUDAPrefetcher, ImageDataset\n",
    "from utils import accuracy, load_state_dict, make_directory, save_checkpoint, Summary, AverageMeter, ProgressMeter\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's see the code that we will utilize to build our training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset() -> [CUDAPrefetcher, CUDAPrefetcher]:\n",
    "    \n",
    "    # Get the training and validation datasets\n",
    "    train_dataset = ImageDataset(config.train_image_dir, config.image_size, \"Train\")\n",
    "    valid_dataset = ImageDataset(config.valid_image_dir, config.image_size, \"Valid\")\n",
    "\n",
    "    # Create dataloaders to efficiently load and batch the data\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=config.batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=config.num_workers,\n",
    "                                  pin_memory=True,\n",
    "                                  drop_last=True,\n",
    "                                  persistent_workers=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset,\n",
    "                                  batch_size=config.batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=config.num_workers,\n",
    "                                  pin_memory=True,\n",
    "                                  drop_last=False,\n",
    "                                  persistent_workers=True)\n",
    "\n",
    "    # Optimize the loading pipeline by prefetching data batches on the GPU\n",
    "    train_prefetcher = CUDAPrefetcher(train_dataloader, config.device)\n",
    "    valid_prefetcher = CUDAPrefetcher(valid_dataloader, config.device)\n",
    "\n",
    "    return train_prefetcher, valid_prefetcher\n",
    "\n",
    "\n",
    "def build_model() -> [nn.Module, nn.Module]:\n",
    "\n",
    "    # Initialize the GoogLeNet model\n",
    "    googlenet_model = model.__dict__[config.model_arch_name](num_classes=config.model_num_classes, aux_logits=False, transform_input=True)\n",
    "\n",
    "    # Move the model to the appropriate device + format\n",
    "    googlenet_model = googlenet_model.to(device=config.device, memory_format=torch.channels_last)\n",
    "\n",
    "    # The exponential moving average (EMA) function\n",
    "    ema_avg = lambda averaged_model_parameter, model_parameter, num_averaged: (1 - config.model_ema_decay) * averaged_model_parameter + config.model_ema_decay * model_parameter\n",
    "\n",
    "    # Initialize the EMA model\n",
    "    ema_googlenet_model = AveragedModel(googlenet_model, avg_fn=ema_avg)\n",
    "\n",
    "    return googlenet_model, ema_googlenet_model\n",
    "\n",
    "\n",
    "def define_loss() -> nn.CrossEntropyLoss:\n",
    "\n",
    "    # Initialize a cross entropy loss model\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=config.loss_label_smoothing)\n",
    "\n",
    "    # Move the model to the appropriate device + format\n",
    "    criterion = criterion.to(device=config.device, memory_format=torch.channels_last)\n",
    "\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def define_optimizer(model) -> optim.SGD:\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.model_lr, momentum=config.model_momentum, weight_decay=config.model_weight_decay)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def define_scheduler(optimizer: optim.SGD) -> lr_scheduler.CosineAnnealingWarmRestarts:\n",
    "\n",
    "    # Initialize a Learning Rate scheduler\n",
    "    scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
    "                                                         config.lr_scheduler_T_0,\n",
    "                                                         config.lr_scheduler_T_mult,\n",
    "                                                         config.lr_scheduler_eta_min)\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of functions so let's go through what each one does.\n",
    "\n",
    "`load_dataset()` : downloads and process the ImageNet dataset in the most optimal way (by pipelining the process on the GPU).\n",
    "\n",
    "`build_model()` : sets up the model by retreiving the `googlenet` class with the configured setting (arguments in `()`)\n",
    "\n",
    "In addition, the model also sets up a Exponential Moving Average (EMA) mode. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
